{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting syft==0.3.0\n",
      "  Using cached syft-0.3.0-py2.py3-none-any.whl (289 kB)\n",
      "Requirement already satisfied: torchvision in d:\\anaconda3\\envs\\spam_classifier\\lib\\site-packages (from syft==0.3.0) (0.5.0+cu92)\n",
      "Requirement already satisfied: websockets in d:\\anaconda3\\envs\\spam_classifier\\lib\\site-packages (from syft==0.3.0) (8.1)\n",
      "Collecting dpcontracts\n",
      "  Using cached dpcontracts-0.6.0-py3-none-any.whl\n",
      "Requirement already satisfied: pandas in d:\\anaconda3\\envs\\spam_classifier\\lib\\site-packages (from syft==0.3.0) (1.3.5)\n",
      "Requirement already satisfied: requests in d:\\anaconda3\\envs\\spam_classifier\\lib\\site-packages (from syft==0.3.0) (2.22.0)\n",
      "Requirement already satisfied: flask in d:\\anaconda3\\envs\\spam_classifier\\lib\\site-packages (from syft==0.3.0) (1.1.4)\n",
      "Requirement already satisfied: torch>=1.5 in d:\\anaconda3\\envs\\spam_classifier\\lib\\site-packages (from syft==0.3.0) (1.11.0)\n",
      "Requirement already satisfied: aiortc in d:\\anaconda3\\envs\\spam_classifier\\lib\\site-packages (from syft==0.3.0) (0.9.28)\n",
      "Collecting sqlitedict\n",
      "  Using cached sqlitedict-2.0.0-py3-none-any.whl\n",
      "Collecting dataclasses\n",
      "  Using cached dataclasses-0.6-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: typing-extensions in d:\\anaconda3\\envs\\spam_classifier\\lib\\site-packages (from syft==0.3.0) (4.0.1)\n",
      "Collecting PyNaCl\n",
      "  Using cached PyNaCl-1.5.0-cp36-abi3-win_amd64.whl (212 kB)\n",
      "Requirement already satisfied: nest-asyncio in d:\\anaconda3\\envs\\spam_classifier\\lib\\site-packages (from syft==0.3.0) (1.5.4)\n",
      "Requirement already satisfied: packaging in d:\\anaconda3\\envs\\spam_classifier\\lib\\site-packages (from syft==0.3.0) (21.3)\n",
      "Collecting typeguard\n",
      "  Using cached typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: protobuf in d:\\anaconda3\\envs\\spam_classifier\\lib\\site-packages (from syft==0.3.0) (3.19.3)\n",
      "Collecting forbiddenfruit>=0.1.3\n",
      "  Using cached forbiddenfruit-0.1.4-py3-none-any.whl\n",
      "Collecting loguru\n",
      "  Using cached loguru-0.6.0-py3-none-any.whl (58 kB)\n",
      "Requirement already satisfied: pyee>=6.0.0 in d:\\anaconda3\\envs\\spam_classifier\\lib\\site-packages (from aiortc->syft==0.3.0) (9.0.3)\n",
      "Requirement already satisfied: cryptography>=2.2 in d:\\anaconda3\\envs\\spam_classifier\\lib\\site-packages (from aiortc->syft==0.3.0) (36.0.1)\n",
      "Requirement already satisfied: pylibsrtp>=0.5.6 in d:\\anaconda3\\envs\\spam_classifier\\lib\\site-packages (from aiortc->syft==0.3.0) (0.7.0)\n",
      "Requirement already satisfied: cffi>=1.0.0 in d:\\anaconda3\\envs\\spam_classifier\\lib\\site-packages (from aiortc->syft==0.3.0) (1.15.0)\n",
      "Requirement already satisfied: av<9.0.0,>=8.0.0 in d:\\anaconda3\\envs\\spam_classifier\\lib\\site-packages (from aiortc->syft==0.3.0) (8.1.0)\n",
      "Requirement already satisfied: crc32c in d:\\anaconda3\\envs\\spam_classifier\\lib\\site-packages (from aiortc->syft==0.3.0) (2.2.post0)\n",
      "Requirement already satisfied: aioice<0.7.0,>=0.6.17 in d:\\anaconda3\\envs\\spam_classifier\\lib\\site-packages (from aiortc->syft==0.3.0) (0.6.18)\n",
      "Requirement already satisfied: netifaces in d:\\anaconda3\\envs\\spam_classifier\\lib\\site-packages (from aioice<0.7.0,>=0.6.17->aiortc->syft==0.3.0) (0.11.0)\n",
      "Requirement already satisfied: pycparser in d:\\anaconda3\\envs\\spam_classifier\\lib\\site-packages (from cffi>=1.0.0->aiortc->syft==0.3.0) (2.21)\n",
      "Requirement already satisfied: click<8.0,>=5.1 in d:\\anaconda3\\envs\\spam_classifier\\lib\\site-packages (from flask->syft==0.3.0) (7.1.2)\n",
      "Requirement already satisfied: Werkzeug<2.0,>=0.15 in d:\\anaconda3\\envs\\spam_classifier\\lib\\site-packages (from flask->syft==0.3.0) (1.0.1)\n",
      "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in d:\\anaconda3\\envs\\spam_classifier\\lib\\site-packages (from flask->syft==0.3.0) (2.11.3)\n",
      "Requirement already satisfied: itsdangerous<2.0,>=0.24 in d:\\anaconda3\\envs\\spam_classifier\\lib\\site-packages (from flask->syft==0.3.0) (1.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in d:\\anaconda3\\envs\\spam_classifier\\lib\\site-packages (from Jinja2<3.0,>=2.10.1->flask->syft==0.3.0) (2.0.1)\n",
      "Requirement already satisfied: win32-setctime>=1.0.0 in d:\\anaconda3\\envs\\spam_classifier\\lib\\site-packages (from loguru->syft==0.3.0) (1.1.0)\n",
      "Requirement already satisfied: colorama>=0.3.4 in d:\\anaconda3\\envs\\spam_classifier\\lib\\site-packages (from loguru->syft==0.3.0) (0.4.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in d:\\anaconda3\\envs\\spam_classifier\\lib\\site-packages (from packaging->syft==0.3.0) (3.0.6)\n",
      "Requirement already satisfied: numpy>=1.17.3 in d:\\anaconda3\\envs\\spam_classifier\\lib\\site-packages (from pandas->syft==0.3.0) (1.18.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in d:\\anaconda3\\envs\\spam_classifier\\lib\\site-packages (from pandas->syft==0.3.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in d:\\anaconda3\\envs\\spam_classifier\\lib\\site-packages (from pandas->syft==0.3.0) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in d:\\anaconda3\\envs\\spam_classifier\\lib\\site-packages (from python-dateutil>=2.7.3->pandas->syft==0.3.0) (1.16.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in d:\\anaconda3\\envs\\spam_classifier\\lib\\site-packages (from requests->syft==0.3.0) (1.25.11)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in d:\\anaconda3\\envs\\spam_classifier\\lib\\site-packages (from requests->syft==0.3.0) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda3\\envs\\spam_classifier\\lib\\site-packages (from requests->syft==0.3.0) (2021.10.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in d:\\anaconda3\\envs\\spam_classifier\\lib\\site-packages (from requests->syft==0.3.0) (3.0.4)\n",
      "Requirement already satisfied: pillow>=4.1.1 in d:\\anaconda3\\envs\\spam_classifier\\lib\\site-packages (from torchvision->syft==0.3.0) (9.0.0)\n",
      "Installing collected packages: typeguard, sqlitedict, PyNaCl, loguru, forbiddenfruit, dpcontracts, dataclasses, syft\n",
      "  Attempting uninstall: syft\n",
      "    Found existing installation: syft 0.2.9\n",
      "    Uninstalling syft-0.2.9:\n",
      "      Successfully uninstalled syft-0.2.9\n",
      "Successfully installed PyNaCl-1.5.0 dataclasses-0.6 dpcontracts-0.6.0 forbiddenfruit-0.1.4 loguru-0.6.0 sqlitedict-2.0.0 syft-0.3.0 typeguard-2.13.3\n"
     ]
    }
   ],
   "source": [
    "# !pip install syft==0.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_C' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-b604c38157ef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mth\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mopacus\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPrivacyEngine\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\spam_classifier\\lib\\site-packages\\torch\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m __all__ += [name for name in dir(_C)\n\u001b[0m\u001b[0;32m     84\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'_'\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m             not name.endswith('Base')]\n",
      "\u001b[1;31mNameError\u001b[0m: name '_C' is not defined"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "import torch as th\n",
    "from torchvision import datasets, transforms\n",
    "from opacus import PrivacyEngine \n",
    "import syft as sy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_sparse' from 'torch._C' (d:\\anaconda3\\envs\\spam_classifier\\lib\\site-packages\\torch\\_C.cp37-win_amd64.pyd)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a1fe3a288712>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mth\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mopacus\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPrivacyEngine\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\spam_classifier\\lib\\site-packages\\torch\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[1;31m# Shared memory manager needs to know the exact location of manager executable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 267\u001b[1;33m \u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initExtension\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmanager_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    268\u001b[0m \u001b[1;32mdel\u001b[0m \u001b[0mmanager_path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\spam_classifier\\lib\\site-packages\\torch\\sparse\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_add_docstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_sparse\u001b[0m  \u001b[1;31m# type: ignore[attr-defined]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name '_sparse' from 'torch._C' (d:\\anaconda3\\envs\\spam_classifier\\lib\\site-packages\\torch\\_C.cp37-win_amd64.pyd)"
     ]
    }
   ],
   "source": [
    "hook = sy.TorchHook(th)\n",
    "alice = sy.VirtualWorker(hook, id=\"alice\")\n",
    "bob = sy.VirtualWorker(hook, id=\"bob\")\n",
    "workers = [alice, bob]\n",
    "\n",
    "sy.local_worker.is_client_worker = False\n",
    "\n",
    "\n",
    "print(workers)\n",
    "train_datasets = datasets.MNIST('../mnist',\n",
    "                 train=True, download=True,\n",
    "                 transform=transforms.Compose([transforms.ToTensor(),\n",
    "                 transforms.Normalize((0.1307,), (0.3081,)),])\n",
    "                 ).federate(workers=workers)\n",
    "\n",
    "\n",
    "# federated_train_datasets = sy.FederatedDataset([train_datasets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model():\n",
    "    return th.nn.Sequential(\n",
    "        th.nn.Conv2d(1, 16, 8, 2, padding=3),\n",
    "        th.nn.ReLU(),\n",
    "        th.nn.MaxPool2d(2, 1),\n",
    "        th.nn.Conv2d(16, 32, 4, 2),\n",
    "        th.nn.ReLU(),\n",
    "        th.nn.MaxPool2d(2, 1),\n",
    "        th.nn.Flatten(), \n",
    "        th.nn.Linear(32 * 4 * 4, 32),\n",
    "        th.nn.ReLU(),\n",
    "        th.nn.Linear(32, 10)\n",
    "    )\n",
    "\n",
    "# the local version that we will use to do the aggregation\n",
    "local_model = make_model()\n",
    "\n",
    "models, dataloaders, optimizers, privacy_engines = [], [], [], []\n",
    "for worker in workers:\n",
    "    model = make_model()\n",
    "    optimizer = th.optim.SGD(model.parameters(), lr=0.1)\n",
    "    model.send(worker)\n",
    "    dataset = train_datasets[worker.id]\n",
    "    # dataloader = sy.FederatedDataLoader(dataset, batch_size=128, shuffle=True, drop_last=True)\n",
    "    dataloader = th.utils.data.DataLoader(dataset, batch_size=128, shuffle=True, drop_last=True)\n",
    "    privacy_engine = PrivacyEngine(model,\n",
    "                                   batch_size=128, \n",
    "                                   sample_size=len(dataset), \n",
    "                                   alphas=range(2,32), \n",
    "                                   noise_multiplier=1.2,\n",
    "                                   max_grad_norm=1.0)\n",
    "    privacy_engine.attach(optimizer)\n",
    "    \n",
    "    models.append(model)\n",
    "    dataloaders.append(dataloader)\n",
    "    optimizers.append(optimizer)\n",
    "    privacy_engines.append(privacy_engine)\n",
    "    \n",
    "def send_new_models(local_model, models):\n",
    "    with th.no_grad():\n",
    "        for remote_model in models:\n",
    "            for new_param, remote_param in zip(local_model.parameters(), remote_model.parameters()):\n",
    "                worker = remote_param.location\n",
    "                remote_value = new_param.send(worker)\n",
    "                remote_param.set_(remote_value)\n",
    "\n",
    "            \n",
    "def federated_aggregation(local_model, models):\n",
    "    with th.no_grad():\n",
    "        for local_param, *remote_params in zip(*([local_model.parameters()] + [model.parameters() for model in models])):\n",
    "            param_stack = th.zeros(*remote_params[0].shape)\n",
    "            for remote_param in remote_params:\n",
    "                param_stack += remote_param.copy().get()\n",
    "            param_stack /= len(remote_params)\n",
    "            local_param.set_(param_stack)\n",
    "\n",
    "def train(epoch, delta):\n",
    "        \n",
    "    # 1. Send new version of the model\n",
    "    send_new_models(local_model, models)\n",
    "\n",
    "    # 2. Train remotely the models\n",
    "    for i, worker in enumerate(workers):\n",
    "        dataloader = dataloaders[i]\n",
    "        model = models[i]\n",
    "        optimizer = optimizers[i]\n",
    "        \n",
    "        model.train()\n",
    "        criterion = th.nn.CrossEntropyLoss()\n",
    "        losses = []   \n",
    "        for i, (data, target) in enumerate(tqdm(dataloader)):\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # optimizer.virtual_step()\n",
    "            losses.append(loss.get().item()) \n",
    "\n",
    "        sy.local_worker.clear_objects()\n",
    "        epsilon, best_alpha = optimizer.privacy_engine.get_privacy_spent(delta) \n",
    "        print(\n",
    "            f\"[{worker.id}]\\t\"\n",
    "            f\"Train Epoch: {epoch} \\t\"\n",
    "            f\"Loss: {sum(losses)/len(losses):.4f} \"\n",
    "            f\"(ε = {epsilon:.2f}, δ = {delta}) for α = {best_alpha}\")\n",
    "\n",
    "    # 3. Federated aggregation of the updated models\n",
    "    federated_aggregation(local_model, models)\n",
    "\n",
    "for epoch in range(5):\n",
    "    train(epoch, delta=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-54701781ccf2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'sy' is not defined"
     ]
    }
   ],
   "source": [
    "print(sy.__version__)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "27726a6b9d0b3aecf19ddb8fb5d165165384e9a9dccccc704489801e8c9c2418"
  },
  "kernelspec": {
   "display_name": "Python 3.7.5 ('spam_classifier')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

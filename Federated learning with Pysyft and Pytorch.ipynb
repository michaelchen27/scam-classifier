{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T19:33:40.160008Z",
     "start_time": "2019-06-03T19:33:39.344527Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import sqrt, argmax\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "\n",
    "import syft as sy\n",
    "\n",
    "import warnings\n",
    "from pprint import pprint\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from handcrafted_GRU import GRU\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Device:{device}\")\n",
    "\n",
    "print(f\"Torch Ver: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS = set(stopwords.words('indonesian'))\n",
    "# print(f\"STOPWORDS:\\n {STOPWORDS}\")\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    text = ' '.join([word for word in text.split() if word not in STOPWORDS])\n",
    "    return text\n",
    "\n",
    "def tokenize(text, word_to_idx):\n",
    "    tokens = []\n",
    "    for word in text.split():\n",
    "        if word in word_to_idx:\n",
    "            tokens.append(word_to_idx[word])\n",
    "        else:\n",
    "            tokens.append(0)\n",
    "    return tokens\n",
    "\n",
    "def pad_and_truncate(messages, max_length=30):\n",
    "    features = np.zeros((len(messages), max_length), dtype=int)\n",
    "    for i, sms in enumerate(messages):\n",
    "        if len(sms):\n",
    "            features[i, -len(sms):] = sms[:max_length]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    data = pd.read_csv('train_sms_1240.csv', sep=',', names=['Teks', 'Label'], encoding= 'unicode_escape')\n",
    "    # Lowercase, remove unnecessary char with regex, remove stop words\n",
    "    data.Teks = data.Teks.apply(clean_text)\n",
    "    words = set((' '.join(data.Teks)).split())\n",
    "    word_to_idx = {word: i for i, word in enumerate(words, start=1)}\n",
    "    tokens = data.Teks.apply(lambda x: tokenize(x, word_to_idx))\n",
    "    inputs = pad_and_truncate(tokens)\n",
    "    labels = np.array((data.Label == '1').astype(int))\n",
    "\n",
    "    np.save('labels.npy', labels)\n",
    "    np.save('inputs.npy', inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training model with Federated learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and model hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T19:33:40.207763Z",
     "start_time": "2019-06-03T19:33:40.201292Z"
    }
   },
   "outputs": [],
   "source": [
    "# Training params\n",
    "TRAIN_VOCAB_SIZE = int(inputs.max()) + 1\n",
    "EPOCHS = 100\n",
    "CLIP = 5 # gradient clipping - to avoid gradient explosion (frequent in RNNs)\n",
    "lr = 0.1\n",
    "BATCH_SIZE = 30\n",
    "\n",
    "# Model params\n",
    "EMBEDDING_DIM = 50\n",
    "HIDDEN_DIM = 10\n",
    "DROPOUT = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T19:33:40.197935Z",
     "start_time": "2019-06-03T19:33:40.186270Z"
    }
   },
   "outputs": [],
   "source": [
    "original_inputs = np.load('inputs.npy')\n",
    "original_labels = np.load('labels.npy')\n",
    "\n",
    "inputs = torch.tensor(original_inputs)\n",
    "labels = torch.tensor(original_labels)\n",
    "\n",
    "# splitting training and test data\n",
    "# 20% of the data will be for Tests.\n",
    "pct_test = 0.2\n",
    "\n",
    "#20% of total data\n",
    "pct_test_count = -int(len(labels)*pct_test)\n",
    "\n",
    "# Get 80% of Train LABELS from left.\n",
    "train_labels = labels[:pct_test_count]\n",
    "print(f\"Train Labels: [:{pct_test_count}]\")\n",
    "\n",
    "# Get 80% of Train INPUTS from left.\n",
    "train_inputs = inputs[:pct_test_count]\n",
    "print(f\"Train Inputs: [:{pct_test_count}]\")\n",
    "\n",
    "# Get the rest of the LABEL data for test on the right (20%) \n",
    "test_labels = labels[pct_test_count:]\n",
    "print(f\"Test Labels: [{pct_test_count}:]\")\n",
    "\n",
    "# Get the rest of the INPUT data for test on the right (20%)\n",
    "test_inputs = inputs[pct_test_count:]\n",
    "print(f\"Test Inputs: [{pct_test_count}:]\")\n",
    "\n",
    "\n",
    "SAMPLE_SIZE = len(labels)\n",
    "print(f\"Sample Size: {SAMPLE_SIZE}\")\n",
    "\n",
    "print(f\"20% of Sample Size: {SAMPLE_SIZE*pct_test}\")\n",
    "\n",
    "# For Local Model Evaluation\n",
    "original_test_inputs = original_inputs[pct_test_count:]\n",
    "original_test_labels = original_labels[pct_test_count:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VirtualWorkers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T19:33:42.591430Z",
     "start_time": "2019-06-03T19:33:41.969220Z"
    }
   },
   "outputs": [],
   "source": [
    "# Hook that extends the Pytorch library \n",
    "# to enable all computations with pointers of tensors sent to other workers\n",
    "hook = sy.TorchHook(torch)\n",
    "\n",
    "# Creating 2 virtual workers Syft v0.2.9\n",
    "anne = sy.VirtualWorker(hook, id=\"anne\")\n",
    "bob = sy.VirtualWorker(hook, id=\"bob\")\n",
    "\n",
    "workers = [anne, bob]\n",
    "\n",
    "# threshold indexes for dataset split (one half for Bob, other half for Anne)\n",
    "train_idx = int(len(train_labels)/2)\n",
    "test_idx = int(len(test_labels)/2)\n",
    "\n",
    "# Sending toy datasets to virtual workers\n",
    "bob_train_dataset = sy.BaseDataset(train_inputs[:train_idx], train_labels[:train_idx]).send(bob)\n",
    "anne_train_dataset = sy.BaseDataset(train_inputs[train_idx:], train_labels[train_idx:]).send(anne)\n",
    "bob_test_dataset = sy.BaseDataset(test_inputs[:test_idx], test_labels[:test_idx]).send(bob)\n",
    "anne_test_dataset = sy.BaseDataset(test_inputs[test_idx:], test_labels[test_idx:]).send(anne)\n",
    "\n",
    "\n",
    "# Creating federated datasets, an extension of Pytorch TensorDataset class \n",
    "# for TRAINING METHOD #1 (with aggregation)\n",
    "bob_federated_train_dataset = sy.FederatedDataset([bob_train_dataset])\n",
    "anne_federated_train_dataset = sy.FederatedDataset([anne_train_dataset])\n",
    "bob_federated_test_dataset = sy.FederatedDataset([bob_test_dataset])\n",
    "anne_federated_test_dataset = sy.FederatedDataset([anne_test_dataset])\n",
    "\n",
    "\n",
    "merged_test_dataset = list(zip(original_test_inputs, original_test_labels))\n",
    "\n",
    "def collate_batch(batch):\n",
    "        text_list, label_list = [], []\n",
    "        for (_text, _label) in batch:\n",
    "                text_list.append(_text)\n",
    "                label_list.append(_label)\n",
    "        return text_list, label_list\n",
    "\n",
    "original_test_dataloader = DataLoader(merged_test_dataset, batch_size=BATCH_SIZE, collate_fn=collate_batch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import GRU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T19:33:42.638046Z",
     "start_time": "2019-06-03T19:33:42.617601Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_model():\n",
    "    model = GRU(vocab_size=TRAIN_VOCAB_SIZE, hidden_dim=HIDDEN_DIM, embedding_dim=EMBEDDING_DIM, dropout=DROPOUT)\n",
    "    return model\n",
    "    \n",
    "local_model = make_model()\n",
    "\n",
    "models, train_dataloaders, test_dataloaders, optimizers, privacy_engines = [], [], [], [], []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attaching model, dataloaders, and optimizers to each worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for worker in workers:\n",
    "    model = make_model()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "    model.send(worker)\n",
    "    if(worker == anne):\n",
    "        train_dataset = anne_federated_train_dataset\n",
    "        test_dataset = anne_federated_test_dataset\n",
    "    elif(worker == bob):\n",
    "        train_dataset = bob_federated_train_dataset\n",
    "        test_dataset = bob_federated_test_dataset\n",
    "\n",
    "\n",
    "    train_dataloader = sy.FederatedDataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "    test_dataloader = sy.FederatedDataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "    models.append(model)\n",
    "    train_dataloaders.append(train_dataloader)\n",
    "    test_dataloaders.append(test_dataloader)\n",
    "    optimizers.append(optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to aggregate remote models and to send new updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def federated_aggregation(local_model, models):\n",
    "    with torch.no_grad():\n",
    "        for local_param, *remote_params in zip(*([local_model.parameters()] + [model.parameters() for model in models])):\n",
    "            param_stack = torch.zeros(*remote_params[0].shape)\n",
    "            for remote_param in remote_params:\n",
    "                param_stack += remote_param.copy().get()\n",
    "            param_stack /= len(remote_params)\n",
    "            local_param.set_(param_stack)\n",
    "\n",
    "def send_new_models(local_model, models):\n",
    "    with torch.no_grad():\n",
    "        for remote_model in models:\n",
    "            for new_param, remote_param in zip(local_model.parameters(), remote_model.parameters()):\n",
    "                worker = remote_param.location\n",
    "                remote_value = new_param.send(worker)\n",
    "                remote_param.set_(remote_value) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Method #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = [[], []]\n",
    "test_losses = []\n",
    "\n",
    "def train(epoch):\n",
    "    # 1. Send new version of the model\n",
    "    send_new_models(local_model, models)\n",
    "\n",
    "    # 2. Train remotely the models\n",
    "    for i, worker in enumerate(workers):\n",
    "        train_dataloader = train_dataloaders[i]\n",
    "        model = models[i]\n",
    "        optimizer = optimizers[i]\n",
    "        \n",
    "        model.train()\n",
    "        criterion = nn.BCELoss() # for two class classification\n",
    "        losses = []   \n",
    "    \n",
    "        for data, target in train_dataloader:            \n",
    "            data = data.to(torch.long)\n",
    "            h = torch.Tensor(torch.zeros(BATCH_SIZE, HIDDEN_DIM)).send(worker)  \n",
    "            \n",
    "            # Call zero grad to clear previous gradient before every training passses.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output, _ = model(data.to(torch.long), h)\n",
    "            loss = criterion(output.squeeze(), target.float())\n",
    "            loss.backward()\n",
    "\n",
    "\n",
    "            losses.append(loss.get()) \n",
    "            optimizer.step()\n",
    "\n",
    "        sy.local_worker.clear_objects()\n",
    "        \n",
    "\n",
    "        train_loss = sum(losses) / len(losses)\n",
    "        train_losses[i].append(train_loss.item())\n",
    "\n",
    "        print(\n",
    "            f\"[{worker.id}]\\t\"\n",
    "            f\"Train Epoch: {epoch+1}/{EPOCHS} \\t\"\n",
    "            f\"Train Loss: {train_loss:.4f} \")\n",
    "\n",
    "    # 3. Federated aggregation of the updated models\n",
    "    federated_aggregation(local_model, models)\n",
    "\n",
    "\n",
    "def eval(epoch, last_loss, trigger_times, patience):\n",
    "    # 4. Evaluate the model\n",
    "    local_model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        test_preds = []\n",
    "        test_labels_list = []\n",
    "        eval_losses = []\n",
    "\n",
    "        for inputs, labels in original_test_dataloader:\n",
    "            h = torch.Tensor(np.zeros((BATCH_SIZE, HIDDEN_DIM)))\n",
    "            output, _ = local_model(torch.LongTensor(inputs), h)\n",
    "            criterion = nn.BCELoss()\n",
    "            labels = torch.LongTensor(labels)\n",
    "            loss = criterion(output.squeeze(), labels.float())\n",
    "            eval_losses.append(loss)\n",
    "            preds = output.squeeze()\n",
    "            test_preds += list(preds.numpy())\n",
    "            test_labels_list += list(labels.numpy().astype(int))\n",
    "    \n",
    "    eval_loss = sum(eval_losses) / len(eval_losses)\n",
    "    test_losses.append(eval_loss.item())\n",
    "\n",
    "            \n",
    "    # Early Stopping\n",
    "    if eval_loss > last_loss:\n",
    "        trigger_times += 1\n",
    "        print(f\"Trigger Times: {trigger_times}\")\n",
    "        \n",
    "        if trigger_times >= patience:\n",
    "            print(\"EARLY STOPPING! STARTING TEST PROCESS...\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Trigger Times: 0\")\n",
    "        trigger_times = 0\n",
    "    \n",
    "    last_loss = eval_loss\n",
    "\n",
    "    print(\n",
    "        f\"Eval Epoch: {epoch} \\t\"\n",
    "        f\"Eval Loss: {eval_loss:.4f} \\n\\n\")\n",
    "\n",
    "    return last_loss, trigger_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Early Stopping\n",
    "last_loss = 100\n",
    "patience = 3\n",
    "trigger_times = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train(epoch)\n",
    "    last_loss, trigger_times = eval(epoch, last_loss, trigger_times, patience)\n",
    "    if trigger_times >= patience:\n",
    "        print(\"EARLY STOPPING! STARTING TEST PROCESS...\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Anne Losses: {train_losses[0]}\\n\")\n",
    "print(f\"Bob Losses: {train_losses[1]}\\n\")\n",
    "print(f\"Test Losses: {test_losses}\\n\")\n",
    "plt.plot(train_losses[0], 'r')\n",
    "plt.plot(train_losses[1], 'g')\n",
    "plt.plot(test_losses, 'b')\n",
    "plt.legend(['Training Loss Anne', 'Training Loss Bob' , 'Eval Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Train Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save First Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "PATH = \"local_state_dict_model.pt\"\n",
    "torch.save(local_model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('test_sms_540.csv', sep=',', encoding= 'unicode_escape', names=['Teks', 'Label'])\n",
    "# Lowercase, remove unnecessary char with regex, remove stop words\n",
    "data.Teks = data.Teks.apply(clean_text)\n",
    "words = set((' '.join(data.Teks)).split())\n",
    "word_to_idx = {word: i for i, word in enumerate(words, start=1)}\n",
    "tokens = data.Teks.apply(lambda x: tokenize(x, word_to_idx))\n",
    "inputs = pad_and_truncate(tokens)\n",
    "labels = np.array((data.Label == '1').astype(int))\n",
    "\n",
    "np.save('test_labels.npy', labels)\n",
    "np.save('test_inputs.npy', inputs)\n",
    "\n",
    "test_inputs = torch.tensor(np.load('test_inputs.npy'))\n",
    "test_labels = torch.tensor(np.load('test_labels.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing params\n",
    "TEST_VOCAB_SIZE = TRAIN_VOCAB_SIZE \n",
    "BATCH_SIZE = 30\n",
    "\n",
    "# Model params\n",
    "EMBEDDING_DIM = 50\n",
    "HIDDEN_DIM = 10\n",
    "DROPOUT = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Test First Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load First Model\n",
    "PATH = \"local_state_dict_model.pt\"\n",
    "load_model =    GRU(vocab_size=TEST_VOCAB_SIZE, \n",
    "                    hidden_dim=HIDDEN_DIM, \n",
    "                    embedding_dim=EMBEDDING_DIM, \n",
    "                    dropout=DROPOUT) \n",
    "\n",
    "load_model.load_state_dict(torch.load(PATH))\n",
    "load_model.eval()\n",
    "print(load_model)\n",
    "\n",
    "# Test Model\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "test_dataset = TensorDataset(test_inputs, test_labels)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "test_losses = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_preds = []\n",
    "    test_labels_list = []\n",
    "    eval_losses = []\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(test_loader):\n",
    "        # print(f\"i: {i}\\nInputs: {inputs} Labels: {labels}\")\n",
    "        h = torch.Tensor(np.zeros((BATCH_SIZE, HIDDEN_DIM)))\n",
    "\n",
    "        output, _ = load_model(inputs.to(torch.long), h)\n",
    "        loss = criterion(output.squeeze(), labels.float())\n",
    "        eval_losses.append(loss)\n",
    "        preds = output.squeeze()\n",
    "        if len(labels) > 1:\n",
    "            test_preds += list(preds.numpy())\n",
    "            test_labels_list += list(labels.numpy().astype(int))\n",
    "\n",
    "\n",
    "roc_acc_score = roc_auc_score(test_labels_list, test_preds)\n",
    "\n",
    "# Calculate ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(test_labels_list, test_preds)\n",
    "# Calculate the g-mean for each threshold\n",
    "gmeans = sqrt(tpr * (1-fpr))\n",
    "# Index of largest G-means\n",
    "ix = argmax(gmeans)\n",
    "print('Best Threshold=%f, G-Mean=%.3f' % (thresholds[ix], gmeans[ix]))\n",
    "threshold = thresholds[ix]\n",
    "\n",
    "# Print how many data is being tested\n",
    "print(f\"Amount of test data: {len(test_labels_list)}\")\n",
    "    \n",
    "print(f\"ROC Accuracy Score: {roc_acc_score}\")\n",
    "\n",
    "# Normalize probability with threshold\n",
    "test_preds_thresholded = np.where(test_preds > threshold, 1, 0)\n",
    "for i in range(len(test_preds)-1140):\n",
    "    print(\"Test Preds Prob: {}    \\\n",
    "    Test Preds Label: {}  \\\n",
    "    True Label: {}  \\\n",
    "    \".format(test_preds[i], test_preds_thresholded[i], test_labels_list[i]))\n",
    "\n",
    "acc_score = accuracy_score(test_labels_list, test_preds_thresholded)\n",
    "print(f\"\\nAccuracy Score: {acc_score}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(test_labels_list, test_preds_thresholded)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7.5, 7.5))\n",
    "ax.matshow(cm, cmap=plt.cm.Blues, alpha=0.3)\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        ax.text(x=j, y=i,s=cm[i, j], va='center', ha='center', size='xx-large')\n",
    " \n",
    "plt.xlabel('Predictions', fontsize=18)\n",
    "plt.ylabel('Actuals', fontsize=18)\n",
    "plt.title('Confusion Matrix', fontsize=18)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nConfusion Matrix: \\n{cm}\")\n",
    "\n",
    "tn = cm[0][0]\n",
    "fp = cm[0][1]\n",
    "fn = cm[1][0]\n",
    "tp = cm[1][1]\n",
    "print(f\"\\nTN: {tn}\\t FP: {fp}\\nFN: {fn}\\t TP: {tp}\\n\")\n",
    "\n",
    "# Precision\n",
    "precision = tp/(tp+fp)\n",
    "print(f\"Precision: {precision}\")\n",
    "\n",
    "# Recall\n",
    "recall = tp/(tp+fn)\n",
    "print(f\"Recall:{recall}\")\n",
    "\n",
    "# Calculate F1 Score\n",
    "f1_score = f1_score(test_labels_list, test_preds_thresholded)\n",
    "print(f\"F1 Score: {f1_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Method #2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, PySyft does not support optimizers with momentum. Therefore, we are going to stick with the classical [Stochastic Gradient Descent](https://pytorch.org/docs/stable/optim.html#torch.optim.SGD) optimizer.\n",
    "\n",
    "As our task consists of a binary classification, we are going to use the [Binary Cross Entropy Loss](https://pytorch.org/docs/stable/nn.html#torch.nn.BCELoss)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T20:00:23.084933Z",
     "start_time": "2019-06-03T20:00:23.078688Z"
    }
   },
   "outputs": [],
   "source": [
    "# Defining loss and optimizer\n",
    "second_model = make_model()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(second_model.parameters(), lr=lr)\n",
    "\n",
    "# Create data\n",
    "# # Creating federated datasets, an extension of Pytorch TensorDataset class\n",
    "federated_train_dataset = sy.FederatedDataset([bob_train_dataset, anne_train_dataset])\n",
    "federated_test_dataset = sy.FederatedDataset([bob_test_dataset, anne_test_dataset])\n",
    "\n",
    "# Creating federated dataloaders, an extension of Pytorch DataLoader class for TRAINIG METHOD #2\n",
    "federated_train_loader = sy.FederatedDataLoader(federated_train_dataset, batch_size=BATCH_SIZE)\n",
    "federated_test_loader = sy.FederatedDataLoader(federated_test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T19:56:01.459697Z",
     "start_time": "2019-06-03T19:33:42.666174Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "# For Early Stopping\n",
    "last_loss = 100\n",
    "patience = 3\n",
    "trigger_times = 0\n",
    "\n",
    "\n",
    "for e in range(EPOCHS):\n",
    "    \n",
    "    ######### Training ##########\n",
    "\n",
    "    losses = []\n",
    "    # Batch loop\n",
    "    for inputs, labels in federated_train_loader:\n",
    "        # Location of current batch\n",
    "        worker = inputs.location\n",
    "        # Initialize hidden state and send it to worker\n",
    "        h = torch.Tensor(np.zeros((BATCH_SIZE, HIDDEN_DIM))).send(worker)\n",
    "        # Send model to current worker\n",
    "        second_model.send(worker)\n",
    "        # Setting accumulated gradients to zero before backward step\n",
    "        optimizer.zero_grad()\n",
    "        # Output from the model\n",
    "        output, _ = second_model(inputs.to(torch.long), h)\n",
    "        # Calculate the loss and perform backprop\n",
    "        loss = criterion(output.squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "        # Backpropagation step\n",
    "        optimizer.step() \n",
    "        # Get the model back to the local worker\n",
    "        second_model.get()\n",
    "        losses.append(loss.get())\n",
    "    \n",
    "    \n",
    "    ######## Evaluation ##########\n",
    "    \n",
    "    # Model in evaluation mode\n",
    "    second_model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        test_preds = []\n",
    "        test_labels_list = []\n",
    "        eval_losses = []\n",
    "\n",
    "        for inputs, labels in federated_test_loader:\n",
    "            # Get current data location\n",
    "            worker = inputs.location\n",
    "            # Initialize hidden state and send it to worker\n",
    "            h = torch.Tensor(np.zeros((BATCH_SIZE, HIDDEN_DIM))).send(worker)    \n",
    "            # Send model to worker\n",
    "            second_model.send(worker)\n",
    "            output, _ = second_model(inputs.to(torch.long), h)\n",
    "            loss = criterion(output, labels.float())\n",
    "            eval_losses.append(loss.get())\n",
    "            preds = output.squeeze().get()\n",
    "            test_preds += list(preds.numpy())\n",
    "            test_labels_list += list(labels.get().numpy().astype(int))\n",
    "            # Get the model back to the local worker\n",
    "            second_model.get()\n",
    "\n",
    "\n",
    "    # Check test preds\n",
    "    train_loss = sum(losses)/len(losses)\n",
    "    eval_loss = sum(eval_losses)/len(eval_losses)\n",
    "    \n",
    "    train_losses.append(train_loss.item())\n",
    "    test_losses.append(eval_loss.item())\n",
    "    \n",
    "    print(\"Epoch {}/{}...  \\\n",
    "    Training loss: {:.5f}...  \\\n",
    "    Validation loss: {:.5f}\".format(e+1, EPOCHS, train_loss, eval_loss))\n",
    "        \n",
    "    # Early Stopping\n",
    "    if eval_loss > last_loss:\n",
    "        trigger_times += 1\n",
    "        print(f\"Trigger Times: {trigger_times}\")\n",
    "        \n",
    "        if trigger_times >= patience:\n",
    "            print(\"EARLY STOPPING! STARTING TEST PROCESS...\")\n",
    "            break\n",
    "    else:\n",
    "        print(f\"Trigger Times: 0\")\n",
    "        trigger_times = 0\n",
    "    \n",
    "    last_loss = eval_loss\n",
    "    \n",
    "    second_model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Training Method #2 Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Train Losses: {train_losses}\")\n",
    "print(f\"Test Losses: {test_losses}\")\n",
    "plt.plot(train_losses, 'r')\n",
    "plt.plot(test_losses, 'g')\n",
    "plt.legend(['Train Loss', 'Eval Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Train Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving second model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "PATH = \"state_dict_model.pt\"\n",
    "torch.save(second_model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing params\n",
    "VOCAB_SIZE = int(test_inputs.max()) + 1\n",
    "TEST_VOCAB_SIZE = TRAIN_VOCAB_SIZE\n",
    "BATCH_SIZE = 30\n",
    "\n",
    "# Model params\n",
    "EMBEDDING_DIM = 50\n",
    "HIDDEN_DIM = 10\n",
    "DROPOUT = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Second Model\n",
    "PATH = \"state_dict_model.pt\"\n",
    "load_model = GRU(vocab_size=TEST_VOCAB_SIZE, \n",
    "                hidden_dim=HIDDEN_DIM, \n",
    "                embedding_dim=EMBEDDING_DIM, \n",
    "                dropout=DROPOUT)\n",
    "load_model.load_state_dict(torch.load(PATH))\n",
    "load_model.eval()\n",
    "\n",
    "# Test Model\n",
    "from sklearn.metrics import f1_score\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "test_dataset = TensorDataset(test_inputs, test_labels)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "test_losses = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_preds = []\n",
    "    test_labels_list = []\n",
    "    eval_losses = []\n",
    "\n",
    "    for inputs, labels in test_loader:\n",
    "        h = torch.Tensor(np.zeros((BATCH_SIZE, HIDDEN_DIM)))\n",
    "        output, _ = second_model(inputs.to(torch.long), h)\n",
    "        loss = criterion(output.squeeze(), labels.float())\n",
    "        eval_losses.append(loss)\n",
    "        preds = output.squeeze()\n",
    "        if len(labels) > 1:\n",
    "            test_preds += list(preds.numpy())\n",
    "            test_labels_list += list(labels.numpy().astype(int))\n",
    "\n",
    "\n",
    "roc_acc_score = roc_auc_score(test_labels_list, test_preds)\n",
    "\n",
    "# Calculate ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(test_labels_list, test_preds)\n",
    "# calculate the g-mean for each threshold\n",
    "gmeans = sqrt(tpr * (1-fpr))\n",
    "# Index of largest G-means\n",
    "ix = argmax(gmeans)\n",
    "print('Best Threshold=%f, G-Mean=%.3f' % (thresholds[ix], gmeans[ix]))\n",
    "threshold = thresholds[ix]\n",
    "\n",
    "# Print how many data is being tested\n",
    "print(f\"Amount of test data: {len(test_labels_list)}\")\n",
    "\n",
    "\n",
    "# Plot ROC Curve\n",
    "plt.plot([0,1], [0,1], linestyle='--', label='No Skill')\n",
    "plt.plot(fpr, tpr, marker='.', label='Logistic')\n",
    "# axis labels\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "# show the plot\n",
    "plt.show()\n",
    "\n",
    "    \n",
    "print(f\"ROC Accuracy Score: {roc_acc_score}\")\n",
    "\n",
    "# Normalize probability with threshold\n",
    "test_preds_thresholded = np.where(test_preds > threshold, 1, 0)\n",
    "for i in range(len(test_preds)-1140):\n",
    "    print(\"Test Preds Prob: {}    \\\n",
    "    Test Preds Label: {}  \\\n",
    "    True Label: {}  \\\n",
    "    \".format(test_preds[i], test_preds_thresholded[i], test_labels_list[i]))\n",
    "\n",
    "acc_score = accuracy_score(test_labels_list, test_preds_thresholded)\n",
    "print(f\"\\nAccuracy Score: {acc_score}\")\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(test_labels_list, test_preds_thresholded)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7.5, 7.5))\n",
    "ax.matshow(cm, cmap=plt.cm.Blues, alpha=0.3)\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        ax.text(x=j, y=i,s=cm[i, j], va='center', ha='center', size='xx-large')\n",
    " \n",
    "plt.xlabel('Predictions', fontsize=18)\n",
    "plt.ylabel('Actuals', fontsize=18)\n",
    "plt.title('Confusion Matrix', fontsize=18)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nConfusion Matrix: \\n{cm}\")\n",
    "\n",
    "tn = cm[0][0]\n",
    "fp = cm[0][1]\n",
    "fn = cm[1][0]\n",
    "tp = cm[1][1]\n",
    "print(f\"\\nTN: {tn}\\t FP: {fp}\\nFN: {fn}\\t TP: {tp}\\n\")\n",
    "\n",
    "# Precision\n",
    "precision = tp/(tp+fp)\n",
    "print(f\"Precision: {precision}\")\n",
    "\n",
    "# Recall\n",
    "recall = tp/(tp+fn)\n",
    "print(f\"Recall:{recall}\")\n",
    "\n",
    "# Calculate F1 Score\n",
    "f1_score = f1_score(test_labels_list, test_preds_thresholded)\n",
    "print(f\"F1 Score: {f1_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_threshold = threshold\n",
    "\n",
    "# Load Second Model\n",
    "infer_model = GRU(vocab_size=4281, \n",
    "                hidden_dim=10, \n",
    "                embedding_dim=50, \n",
    "                dropout=0.2)\n",
    "infer_model.load_state_dict(torch.load(\"state_dict_model.pt\"))\n",
    "infer_model.eval()\n",
    "\n",
    "sentence = input()\n",
    "\n",
    "def pre_process(text):\n",
    "    text = clean_text(text)\n",
    "    print(f\"Text: {text}\\n\")\n",
    "\n",
    "    words = text.split()\n",
    "    print(f\"Words: {words}\\n\")\n",
    "\n",
    "    token = lambda x: tokenize (x, word_to_idx)\n",
    "    token_result = token(text)\n",
    "    print(f\"Tokenization Result: {token_result}\")\n",
    "\n",
    "    arr = []\n",
    "    arr.append(token_result)\n",
    "    inputs = pad_and_truncate(arr)\n",
    "    print(inputs)\n",
    "\n",
    "    input = torch.tensor(inputs)\n",
    "    print(input)\n",
    "    return input\n",
    "\n",
    "with torch.no_grad():\n",
    "    infer_sentence = pre_process(sentence)\n",
    "    print(f\"Infer Sentence: {infer_sentence}\")\n",
    "    h = torch.Tensor(np.zeros((1, 10)))\n",
    "\n",
    "    output, _ = infer_model(infer_sentence.to(torch.long), h)\n",
    "    print(f\"\\nOutput: {output.squeeze()}\")\n",
    "\n",
    "    if output > model_threshold:\n",
    "        print(\"Sentence is a Scam\")\n",
    "    else:\n",
    "        print(\"Sentence is NOT a Scam\")"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "interpreter": {
   "hash": "27726a6b9d0b3aecf19ddb8fb5d165165384e9a9dccccc704489801e8c9c2418"
  },
  "kernelspec": {
   "display_name": "Python 3.7.5 ('spam_classifier')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
